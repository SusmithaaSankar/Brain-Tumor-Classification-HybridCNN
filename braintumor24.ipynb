{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf902295c12a4a3f96ccf623d9a840d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9840e33cb0c64bb7808428a51352f6da",
              "IPY_MODEL_aa58618207f34666a4a8a7ebb66f1517",
              "IPY_MODEL_41c4d14f08554ee99d8520fdd065c4c5"
            ],
            "layout": "IPY_MODEL_50cb0da360ee4a9e9207ad5c6a3c7a5e"
          }
        },
        "9840e33cb0c64bb7808428a51352f6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73cde947903d4b33937d78d4a9dd1b3e",
            "placeholder": "​",
            "style": "IPY_MODEL_f69d73af42f840dbaa8583320bc9cefa",
            "value": "model.safetensors: 100%"
          }
        },
        "aa58618207f34666a4a8a7ebb66f1517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a097671eda31481fa12cf98bfe51854d",
            "max": 114286722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_214af8540ae840b398e3f6891a487e30",
            "value": 114286722
          }
        },
        "41c4d14f08554ee99d8520fdd065c4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a16dcb915934754ac58a60b297e91c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f5a83ff0b8cc4b839fbc8f6cd52da521",
            "value": " 114M/114M [00:00&lt;00:00, 293MB/s]"
          }
        },
        "50cb0da360ee4a9e9207ad5c6a3c7a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73cde947903d4b33937d78d4a9dd1b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f69d73af42f840dbaa8583320bc9cefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a097671eda31481fa12cf98bfe51854d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214af8540ae840b398e3f6891a487e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a16dcb915934754ac58a60b297e91c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a83ff0b8cc4b839fbc8f6cd52da521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0d415edb7364bef80b9ebf9eb710e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dc45cc2866f485fb522eb5038682abb",
              "IPY_MODEL_129abbbf347644f99fe3a3b00697ec88",
              "IPY_MODEL_9000e8630f1241ed910138fb57e7cb7d"
            ],
            "layout": "IPY_MODEL_74ad3359a5414fe59b3c5a4b6aae3d5c"
          }
        },
        "4dc45cc2866f485fb522eb5038682abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09132c8837874fe28d63bbf88716e420",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc6a145d2834d828f27ff3f6fd72de6",
            "value": "config.json: "
          }
        },
        "129abbbf347644f99fe3a3b00697ec88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ff18cbd01e4391a41a90a777661aa5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ee477e54d62407cbbe163c7ee465767",
            "value": 1
          }
        },
        "9000e8630f1241ed910138fb57e7cb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f57d3673cd14a72b334b0a47f1a8f3d",
            "placeholder": "​",
            "style": "IPY_MODEL_303795d2a3284e4c8ab43659d3084496",
            "value": " 71.8k/? [00:00&lt;00:00, 4.63MB/s]"
          }
        },
        "74ad3359a5414fe59b3c5a4b6aae3d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09132c8837874fe28d63bbf88716e420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc6a145d2834d828f27ff3f6fd72de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ff18cbd01e4391a41a90a777661aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5ee477e54d62407cbbe163c7ee465767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f57d3673cd14a72b334b0a47f1a8f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303795d2a3284e4c8ab43659d3084496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e09793d889854f0cbd7fe81d991f72c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b765de635c748c49366aaa8e6e26e08",
              "IPY_MODEL_756e5dcf7fec4f128f44c7d82fe7f270",
              "IPY_MODEL_66e9e4ee5e7946dfab0a2ace6242c550"
            ],
            "layout": "IPY_MODEL_0a339e7aabf64979902375cc5a3a54a5"
          }
        },
        "0b765de635c748c49366aaa8e6e26e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a738cb6421f47f6828403440082e9cd",
            "placeholder": "​",
            "style": "IPY_MODEL_e58b6dd3e9ce4ea79bf932abac5c9daf",
            "value": "model.safetensors: 100%"
          }
        },
        "756e5dcf7fec4f128f44c7d82fe7f270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5c91ca655464ed99ececf942cf4dfd7",
            "max": 113412768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aec65daf951f4f17b789f697f3ff427b",
            "value": 113412768
          }
        },
        "66e9e4ee5e7946dfab0a2ace6242c550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b8f03d63918484b9a2d89425416cc54",
            "placeholder": "​",
            "style": "IPY_MODEL_209fc8f959cf427195e3f7b166f10a25",
            "value": " 113M/113M [00:03&lt;00:00, 28.8MB/s]"
          }
        },
        "0a339e7aabf64979902375cc5a3a54a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a738cb6421f47f6828403440082e9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58b6dd3e9ce4ea79bf932abac5c9daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5c91ca655464ed99ececf942cf4dfd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec65daf951f4f17b789f697f3ff427b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b8f03d63918484b9a2d89425416cc54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "209fc8f959cf427195e3f7b166f10a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmwBc6ilRJLO",
        "outputId": "f6927c02-a62e-4805-9682-a74daf283fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.19)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.34.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision timm matplotlib scikit-learn opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "1f2t5_7lSeRi",
        "outputId": "e32880e6-c684-471e-fb36-f433e8e80113"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cc6b0363-1c89-494c-b617-edbd7e119620\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cc6b0363-1c89-494c-b617-edbd7e119620\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving archive (6).zip to archive (6).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"archive (6).zip\"  # use the uploaded filename exactly\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/brain_tumor_dataset\")\n"
      ],
      "metadata": {
        "id": "xgR2OZ37T3RF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Files inside dataset folder:\")\n",
        "print(os.listdir(\"/content/brain_tumor_dataset\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeCiAjx8T9wV",
        "outputId": "5f18bdff-61a0-4b20-924a-ba183b5a2d68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files inside dataset folder:\n",
            "['Training', 'Testing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),   # resize for EfficientNet/Swin\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]) # normalize\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(\"/content/brain_tumor_dataset/Training\", transform=transform)\n",
        "test_data  = datasets.ImageFolder(\"/content/brain_tumor_dataset/Testing\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_loader  = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"Classes:\", train_data.classes)\n",
        "print(\"Training samples:\", len(train_data))\n",
        "print(\"Testing samples:\", len(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRWzW435UDzt",
        "outputId": "fa1ac9b6-7ce5-4118-aed9-04dae9659fa1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
            "Training samples: 5712\n",
            "Testing samples: 1311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm  # for pretrained Swin Transformer\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(HybridModel, self).__init__()\n",
        "\n",
        "        # --- CNN Block for low-level feature extraction ---\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        # --- Swin Transformer (pretrained) ---\n",
        "        self.swin = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True)\n",
        "        in_features = self.swin.head.in_features\n",
        "        self.swin.head = nn.Identity()  # remove final layer\n",
        "\n",
        "        # --- Fusion of CNN + Swin ---\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features + 64*56*56, 512),  # combine features\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN path\n",
        "        cnn_out = self.cnn(x)\n",
        "        cnn_out = cnn_out.view(cnn_out.size(0), -1)  # flatten\n",
        "\n",
        "        # Swin path\n",
        "        swin_out = self.swin(x)\n",
        "\n",
        "        # Concatenate CNN + Swin features\n",
        "        combined = torch.cat((cnn_out, swin_out), dim=1)\n",
        "\n",
        "        return self.fc(combined)\n"
      ],
      "metadata": {
        "id": "5rLxkRSMUY1A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HybridModel(num_classes=4).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "bf902295c12a4a3f96ccf623d9a840d8",
            "9840e33cb0c64bb7808428a51352f6da",
            "aa58618207f34666a4a8a7ebb66f1517",
            "41c4d14f08554ee99d8520fdd065c4c5",
            "50cb0da360ee4a9e9207ad5c6a3c7a5e",
            "73cde947903d4b33937d78d4a9dd1b3e",
            "f69d73af42f840dbaa8583320bc9cefa",
            "a097671eda31481fa12cf98bfe51854d",
            "214af8540ae840b398e3f6891a487e30",
            "4a16dcb915934754ac58a60b297e91c7",
            "f5a83ff0b8cc4b839fbc8f6cd52da521"
          ]
        },
        "id": "KEDMxDjyUddM",
        "outputId": "75e00989-7d1e-479a-baf3-412979a6503f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf902295c12a4a3f96ccf623d9a840d8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "    # CNN features\n",
        "    cnn_out = self.cnn(x)\n",
        "    cnn_out = self.cnn_fc(cnn_out)\n",
        "\n",
        "    # Swin features\n",
        "    swin_out = self.swin(x)\n",
        "    swin_out = swin_out.view(swin_out.size(0), -1)  # flatten (B, C*H*W)\n",
        "    swin_out = self.swin_fc(swin_out)\n",
        "\n",
        "    # Concatenate\n",
        "    combined = torch.cat((cnn_out, swin_out), dim=1)\n",
        "\n",
        "    return self.fc(combined)\n"
      ],
      "metadata": {
        "id": "O17s-GIwU_Xr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from transformers import SwinModel\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(HybridModel, self).__init__()\n",
        "\n",
        "        # CNN backbone (EfficientNet or ResNet)\n",
        "        cnn_base = models.resnet18(pretrained=True)\n",
        "        self.cnn = nn.Sequential(*list(cnn_base.children())[:-1])  # remove final FC\n",
        "        self.cnn_fc = nn.Linear(cnn_base.fc.in_features, 256)\n",
        "\n",
        "        # Swin Transformer backbone\n",
        "        self.swin = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "        self.swin_fc = nn.Linear(self.swin.config.hidden_size, 256)\n",
        "\n",
        "        # Final classification head\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN forward\n",
        "        cnn_out = self.cnn(x)                      # (B, 512, 1, 1)\n",
        "        cnn_out = cnn_out.view(cnn_out.size(0), -1) # flatten -> (B, 512)\n",
        "        cnn_out = self.cnn_fc(cnn_out)              # (B, 256)\n",
        "\n",
        "        # Swin forward\n",
        "        swin_out = self.swin(x).pooler_output       # already (B, hidden_size)\n",
        "        swin_out = self.swin_fc(swin_out)           # (B, 256)\n",
        "\n",
        "        # Combine\n",
        "        combined = torch.cat((cnn_out, swin_out), dim=1)  # (B, 512)\n",
        "\n",
        "        return self.fc(combined)\n"
      ],
      "metadata": {
        "id": "BckG5hRtVUeP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HybridModel(num_classes=4).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "a0d415edb7364bef80b9ebf9eb710e4e",
            "4dc45cc2866f485fb522eb5038682abb",
            "129abbbf347644f99fe3a3b00697ec88",
            "9000e8630f1241ed910138fb57e7cb7d",
            "74ad3359a5414fe59b3c5a4b6aae3d5c",
            "09132c8837874fe28d63bbf88716e420",
            "1cc6a145d2834d828f27ff3f6fd72de6",
            "f1ff18cbd01e4391a41a90a777661aa5",
            "5ee477e54d62407cbbe163c7ee465767",
            "0f57d3673cd14a72b334b0a47f1a8f3d",
            "303795d2a3284e4c8ab43659d3084496",
            "e09793d889854f0cbd7fe81d991f72c2",
            "0b765de635c748c49366aaa8e6e26e08",
            "756e5dcf7fec4f128f44c7d82fe7f270",
            "66e9e4ee5e7946dfab0a2ace6242c550",
            "0a339e7aabf64979902375cc5a3a54a5",
            "4a738cb6421f47f6828403440082e9cd",
            "e58b6dd3e9ce4ea79bf932abac5c9daf",
            "d5c91ca655464ed99ececf942cf4dfd7",
            "aec65daf951f4f17b789f697f3ff427b",
            "6b8f03d63918484b9a2d89425416cc54",
            "209fc8f959cf427195e3f7b166f10a25"
          ]
        },
        "id": "qkCbrgqMV3el",
        "outputId": "0a4ad419-89fa-4326-ab87-b8d232e23966"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 179MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0d415edb7364bef80b9ebf9eb710e4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e09793d889854f0cbd7fe81d991f72c2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from transformers import SwinModel\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(HybridModel, self).__init__()\n",
        "\n",
        "        # CNN backbone (ResNet18)\n",
        "        self.cnn = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        self.cnn.fc = nn.Identity()  # remove last FC layer\n",
        "\n",
        "        # Swin Transformer backbone\n",
        "        self.swin = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "\n",
        "        # Final classifier (CNN features + Swin features)\n",
        "        self.fc = nn.Linear(512 + self.swin.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN branch\n",
        "        cnn_out = self.cnn(x)  # (batch, 512)\n",
        "\n",
        "        # Swin branch\n",
        "        swin_out = self.swin(x).pooler_output  # (batch, hidden_size)\n",
        "\n",
        "        # Concatenate features\n",
        "        combined = torch.cat((cnn_out, swin_out), dim=1)\n",
        "\n",
        "        return self.fc(combined)\n"
      ],
      "metadata": {
        "id": "vkX6EjQTWO0U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HybridModel(num_classes=4).to(device)\n"
      ],
      "metadata": {
        "id": "mhdgDRqOWm48"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation after each epoch\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss:.4f}, Val Acc: {acc:.2f}%\")\n",
        "\n",
        "    print(\"✅ Training Finished!\")\n",
        "\n",
        "# Run training\n",
        "train_model(model, train_loader, test_loader, criterion, optimizer, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHYfhjNsWzbS",
        "outputId": "c41a4c67-fcaa-48b4-d21e-87fe376b461f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 86.9479, Val Acc: 97.10%\n",
            "Epoch [2/5], Loss: 26.2560, Val Acc: 98.47%\n",
            "Epoch [3/5], Loss: 15.9442, Val Acc: 98.17%\n",
            "Epoch [4/5], Loss: 11.6569, Val Acc: 98.02%\n",
            "Epoch [5/5], Loss: 6.8706, Val Acc: 98.86%\n",
            "✅ Training Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"brain_tumor_hybrid.pth\")\n"
      ],
      "metadata": {
        "id": "TxUJGgK_aH2l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "test_glioma_path = \"/content/brain_tumor_dataset/Testing/glioma\"\n",
        "print(\"Available files:\", os.listdir(test_glioma_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDXhkIyagDrc",
        "outputId": "fd7b699d-99fa-4ca4-d4af-096ca14d2945"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available files: ['Te-gl_0210.jpg', 'Te-gl_0168.jpg', 'Te-gl_0251.jpg', 'Te-gl_0047.jpg', 'Te-gl_0293.jpg', 'Te-gl_0271.jpg', 'Te-gl_0093.jpg', 'Te-gl_0160.jpg', 'Te-gl_0162.jpg', 'Te-gl_0087.jpg', 'Te-gl_0295.jpg', 'Te-gl_0265.jpg', 'Te-gl_0149.jpg', 'Te-gl_0267.jpg', 'Te-gl_0036.jpg', 'Te-gl_0268.jpg', 'Te-gl_0186.jpg', 'Te-gl_0010.jpg', 'Te-gl_0233.jpg', 'Te-gl_0064.jpg', 'Te-gl_0294.jpg', 'Te-gl_0100.jpg', 'Te-gl_0263.jpg', 'Te-gl_0058.jpg', 'Te-gl_0280.jpg', 'Te-gl_0184.jpg', 'Te-gl_0045.jpg', 'Te-gl_0259.jpg', 'Te-gl_0236.jpg', 'Te-gl_0252.jpg', 'Te-gl_0077.jpg', 'Te-gl_0201.jpg', 'Te-gl_0094.jpg', 'Te-gl_0204.jpg', 'Te-gl_0178.jpg', 'Te-gl_0083.jpg', 'Te-gl_0034.jpg', 'Te-gl_0260.jpg', 'Te-gl_0145.jpg', 'Te-gl_0030.jpg', 'Te-gl_0220.jpg', 'Te-gl_0146.jpg', 'Te-gl_0275.jpg', 'Te-gl_0216.jpg', 'Te-gl_0049.jpg', 'Te-gl_0241.jpg', 'Te-gl_0164.jpg', 'Te-gl_0237.jpg', 'Te-gl_0208.jpg', 'Te-gl_0020.jpg', 'Te-gl_0104.jpg', 'Te-gl_0085.jpg', 'Te-gl_0080.jpg', 'Te-gl_0032.jpg', 'Te-gl_0150.jpg', 'Te-gl_0206.jpg', 'Te-gl_0191.jpg', 'Te-gl_0069.jpg', 'Te-gl_0075.jpg', 'Te-gl_0129.jpg', 'Te-gl_0240.jpg', 'Te-gl_0017.jpg', 'Te-gl_0063.jpg', 'Te-gl_0167.jpg', 'Te-gl_0073.jpg', 'Te-gl_0092.jpg', 'Te-gl_0297.jpg', 'Te-gl_0245.jpg', 'Te-gl_0018.jpg', 'Te-gl_0079.jpg', 'Te-glTr_0002.jpg', 'Te-gl_0024.jpg', 'Te-gl_0253.jpg', 'Te-gl_0014.jpg', 'Te-gl_0127.jpg', 'Te-gl_0179.jpg', 'Te-gl_0283.jpg', 'Te-gl_0161.jpg', 'Te-gl_0209.jpg', 'Te-glTr_0003.jpg', 'Te-gl_0218.jpg', 'Te-gl_0277.jpg', 'Te-gl_0217.jpg', 'Te-gl_0139.jpg', 'Te-gl_0048.jpg', 'Te-gl_0289.jpg', 'Te-gl_0101.jpg', 'Te-gl_0176.jpg', 'Te-gl_0213.jpg', 'Te-gl_0130.jpg', 'Te-gl_0143.jpg', 'Te-gl_0286.jpg', 'Te-gl_0133.jpg', 'Te-gl_0187.jpg', 'Te-gl_0153.jpg', 'Te-glTr_0006.jpg', 'Te-gl_0138.jpg', 'Te-gl_0112.jpg', 'Te-gl_0182.jpg', 'Te-gl_0119.jpg', 'Te-gl_0056.jpg', 'Te-gl_0239.jpg', 'Te-gl_0031.jpg', 'Te-gl_0180.jpg', 'Te-gl_0012.jpg', 'Te-gl_0226.jpg', 'Te-gl_0071.jpg', 'Te-gl_0039.jpg', 'Te-gl_0120.jpg', 'Te-gl_0135.jpg', 'Te-gl_0084.jpg', 'Te-gl_0154.jpg', 'Te-gl_0121.jpg', 'Te-gl_0091.jpg', 'Te-gl_0134.jpg', 'Te-gl_0296.jpg', 'Te-gl_0140.jpg', 'Te-gl_0192.jpg', 'Te-gl_0287.jpg', 'Te-gl_0062.jpg', 'Te-gl_0221.jpg', 'Te-gl_0097.jpg', 'Te-gl_0110.jpg', 'Te-gl_0197.jpg', 'Te-gl_0041.jpg', 'Te-gl_0169.jpg', 'Te-gl_0144.jpg', 'Te-gl_0013.jpg', 'Te-gl_0235.jpg', 'Te-gl_0211.jpg', 'Te-gl_0136.jpg', 'Te-gl_0102.jpg', 'Te-gl_0214.jpg', 'Te-gl_0255.jpg', 'Te-gl_0090.jpg', 'Te-gl_0052.jpg', 'Te-gl_0194.jpg', 'Te-gl_0250.jpg', 'Te-gl_0157.jpg', 'Te-gl_0279.jpg', 'Te-gl_0117.jpg', 'Te-gl_0264.jpg', 'Te-gl_0202.jpg', 'Te-gl_0070.jpg', 'Te-gl_0227.jpg', 'Te-gl_0123.jpg', 'Te-gl_0262.jpg', 'Te-gl_0095.jpg', 'Te-gl_0068.jpg', 'Te-gl_0142.jpg', 'Te-gl_0174.jpg', 'Te-gl_0106.jpg', 'Te-gl_0053.jpg', 'Te-gl_0118.jpg', 'Te-gl_0199.jpg', 'Te-gl_0175.jpg', 'Te-gl_0278.jpg', 'Te-gl_0128.jpg', 'Te-gl_0290.jpg', 'Te-gl_0166.jpg', 'Te-gl_0116.jpg', 'Te-gl_0027.jpg', 'Te-gl_0046.jpg', 'Te-gl_0212.jpg', 'Te-gl_0298.jpg', 'Te-gl_0248.jpg', 'Te-gl_0200.jpg', 'Te-gl_0222.jpg', 'Te-gl_0215.jpg', 'Te-gl_0066.jpg', 'Te-gl_0261.jpg', 'Te-gl_0246.jpg', 'Te-gl_0125.jpg', 'Te-gl_0054.jpg', 'Te-gl_0284.jpg', 'Te-gl_0156.jpg', 'Te-gl_0065.jpg', 'Te-gl_0078.jpg', 'Te-gl_0163.jpg', 'Te-gl_0044.jpg', 'Te-gl_0185.jpg', 'Te-gl_0257.jpg', 'Te-gl_0193.jpg', 'Te-gl_0207.jpg', 'Te-gl_0148.jpg', 'Te-glTr_0000.jpg', 'Te-gl_0111.jpg', 'Te-gl_0060.jpg', 'Te-gl_0276.jpg', 'Te-gl_0109.jpg', 'Te-gl_0057.jpg', 'Te-gl_0122.jpg', 'Te-gl_0203.jpg', 'Te-gl_0033.jpg', 'Te-gl_0292.jpg', 'Te-gl_0050.jpg', 'Te-gl_0081.jpg', 'Te-gl_0074.jpg', 'Te-gl_0219.jpg', 'Te-gl_0126.jpg', 'Te-gl_0086.jpg', 'Te-gl_0016.jpg', 'Te-gl_0243.jpg', 'Te-gl_0190.jpg', 'Te-gl_0256.jpg', 'Te-gl_0108.jpg', 'Te-gl_0183.jpg', 'Te-gl_0037.jpg', 'Te-gl_0258.jpg', 'Te-gl_0022.jpg', 'Te-gl_0266.jpg', 'Te-gl_0147.jpg', 'Te-gl_0247.jpg', 'Te-gl_0132.jpg', 'Te-gl_0254.jpg', 'Te-gl_0288.jpg', 'Te-gl_0291.jpg', 'Te-gl_0025.jpg', 'Te-gl_0171.jpg', 'Te-gl_0072.jpg', 'Te-gl_0225.jpg', 'Te-gl_0231.jpg', 'Te-gl_0234.jpg', 'Te-gl_0038.jpg', 'Te-gl_0195.jpg', 'Te-gl_0055.jpg', 'Te-gl_0082.jpg', 'Te-gl_0098.jpg', 'Te-gl_0015.jpg', 'Te-gl_0114.jpg', 'Te-gl_0173.jpg', 'Te-gl_0177.jpg', 'Te-gl_0103.jpg', 'Te-gl_0042.jpg', 'Te-gl_0026.jpg', 'Te-gl_0249.jpg', 'Te-gl_0141.jpg', 'Te-gl_0272.jpg', 'Te-gl_0269.jpg', 'Te-gl_0155.jpg', 'Te-gl_0170.jpg', 'Te-gl_0124.jpg', 'Te-gl_0107.jpg', 'Te-gl_0023.jpg', 'Te-gl_0270.jpg', 'Te-gl_0040.jpg', 'Te-gl_0099.jpg', 'Te-gl_0238.jpg', 'Te-gl_0029.jpg', 'Te-gl_0282.jpg', 'Te-gl_0189.jpg', 'Te-gl_0196.jpg', 'Te-gl_0113.jpg', 'Te-gl_0151.jpg', 'Te-gl_0299.jpg', 'Te-gl_0228.jpg', 'Te-gl_0096.jpg', 'Te-gl_0281.jpg', 'Te-gl_0043.jpg', 'Te-gl_0242.jpg', 'Te-gl_0229.jpg', 'Te-gl_0059.jpg', 'Te-gl_0011.jpg', 'Te-gl_0165.jpg', 'Te-gl_0061.jpg', 'Te-gl_0067.jpg', 'Te-gl_0273.jpg', 'Te-gl_0158.jpg', 'Te-glTr_0008.jpg', 'Te-glTr_0007.jpg', 'Te-glTr_0001.jpg', 'Te-gl_0051.jpg', 'Te-gl_0088.jpg', 'Te-gl_0230.jpg', 'Te-glTr_0009.jpg', 'Te-gl_0028.jpg', 'Te-gl_0035.jpg', 'Te-gl_0223.jpg', 'Te-gl_0115.jpg', 'Te-gl_0205.jpg', 'Te-gl_0076.jpg', 'Te-gl_0232.jpg', 'Te-glTr_0004.jpg', 'Te-gl_0224.jpg', 'Te-gl_0131.jpg', 'Te-gl_0188.jpg', 'Te-gl_0137.jpg', 'Te-gl_0089.jpg', 'Te-gl_0105.jpg', 'Te-gl_0021.jpg', 'Te-gl_0244.jpg', 'Te-gl_0285.jpg', 'Te-gl_0181.jpg', 'Te-gl_0159.jpg', 'Te-gl_0019.jpg', 'Te-gl_0152.jpg', 'Te-gl_0198.jpg', 'Te-gl_0274.jpg', 'Te-gl_0172.jpg', 'Te-glTr_0005.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"brain_tumor_hybrid.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jGzSt05FaZNi",
        "outputId": "70361e55-11ff-42b2-c3c8-3e112263ca46"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d302253b-86e5-41f7-a3f6-d74700912bea\", \"brain_tumor_hybrid.pth\", 155215146)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_v2_s\n",
        "\n",
        "# Example Hybrid model skeleton (adjust according to your training code)\n",
        "class HybridBrainTumorModel(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(HybridBrainTumorModel, self).__init__()\n",
        "        self.cnn = efficientnet_v2_s(weights=None)\n",
        "        self.cnn.classifier = nn.Identity()  # remove original classifier\n",
        "        self.transformer = nn.TransformerEncoderLayer(d_model=1280, nhead=8)\n",
        "        self.fc = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)  # CNN feature extraction\n",
        "        # Here, you may need to reshape / pass through Swin transformer\n",
        "        x = x.flatten(1)  # flatten for FC\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "YvIkw4Occsib"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/brain_tumor_model.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7uTiDdddsac",
        "outputId": "d58a4355-3ea5-4088-d475-fe28bde1f14d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /content/brain_tumor_model.py: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKIebaBTe0xX",
        "outputId": "06495b24-c8b1-4a82-babd-ccb3a7963471"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'archive (6).zip'   brain_tumor_dataset   brain_tumor_hybrid.pth   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/content/brain_tumor_dataset\"  # path to your extracted dataset\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iplTpEpe_bP",
        "outputId": "4466afc9-f232-4c17-a89b-361c8ddd5ba7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Training', 'Testing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/content/brain_tumor_dataset\"\n",
        "print(\"Classes in Training folder:\", os.listdir(os.path.join(dataset_path, \"Training\")))\n",
        "print(\"Classes in Testing folder:\", os.listdir(os.path.join(dataset_path, \"Testing\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfaXSBhQfFGN",
        "outputId": "6e7f66c1-d635-452c-86c8-a080193795d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes in Training folder: ['glioma', 'notumor', 'pituitary', 'meningioma']\n",
            "Classes in Testing folder: ['glioma', 'notumor', 'pituitary', 'meningioma']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# 1️⃣ Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 2️⃣ Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "# 3️⃣ Get one file per class automatically\n",
        "dataset_path = \"/content/brain_tumor_dataset/Testing\"\n",
        "classes = ['glioma', 'notumor', 'pituitary', 'meningioma']\n",
        "test_images = []\n",
        "\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(dataset_path, cls)\n",
        "    files = os.listdir(cls_path)\n",
        "    if files:\n",
        "        test_images.append(os.path.join(cls_path, files[0]))  # pick the first file\n",
        "\n",
        "# 4️⃣ Predict\n",
        "for img_path in test_images:\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_class = torch.argmax(output, dim=1).item()\n",
        "    print(f\"{img_path.split('/')[-1]} -> Predicted class: {classes[pred_class]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1uH80kwglni",
        "outputId": "450a2ca5-555e-47cc-8f9f-06a2f9cc1a9a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Te-gl_0210.jpg -> Predicted class: notumor\n",
            "Te-no_0112.jpg -> Predicted class: notumor\n",
            "Te-pi_0216.jpg -> Predicted class: notumor\n",
            "Te-me_0253.jpg -> Predicted class: notumor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/brain_tumor_hybrid_final.pth\")\n"
      ],
      "metadata": {
        "id": "_EmjdHaShZ1A"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "# Paths\n",
        "dataset_path = \"/content/brain_tumor_dataset/Testing\"\n",
        "classes = ['glioma', 'notumor', 'pituitary', 'meningioma']\n",
        "\n",
        "# Predict\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(dataset_path, cls)\n",
        "    files = os.listdir(cls_path)\n",
        "    if files:\n",
        "        img_path = os.path.join(cls_path, files[0])  # first image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            pred_class = torch.argmax(output, dim=1).item()\n",
        "        print(f\"{img_path.split('/')[-1]} -> Predicted class: {classes[pred_class]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KE7nFxFhdNX",
        "outputId": "392ccbba-d468-4ea6-edb4-15c34bdbff5d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Te-gl_0210.jpg -> Predicted class: notumor\n",
            "Te-no_0112.jpg -> Predicted class: notumor\n",
            "Te-pi_0216.jpg -> Predicted class: notumor\n",
            "Te-me_0253.jpg -> Predicted class: notumor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "# Classes and dataset path\n",
        "dataset_path = \"/content/brain_tumor_dataset/Testing\"\n",
        "classes = ['glioma', 'notumor', 'pituitary', 'meningioma']\n",
        "\n",
        "# Predict first image of each class\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(dataset_path, cls)\n",
        "    files = os.listdir(cls_path)\n",
        "    if files:\n",
        "        img_path = os.path.join(cls_path, files[0])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            pred_class = torch.argmax(output, dim=1).item()\n",
        "        print(f\"{img_path.split('/')[-1]} -> Predicted class: {classes[pred_class]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amXq4Phbh9zD",
        "outputId": "0a6dfa8d-2eaa-470a-fcef-25f6afadf0f3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Te-gl_0210.jpg -> Predicted class: notumor\n",
            "Te-no_0112.jpg -> Predicted class: notumor\n",
            "Te-pi_0216.jpg -> Predicted class: notumor\n",
            "Te-me_0253.jpg -> Predicted class: notumor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict first 3 images per class\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(dataset_path, cls)\n",
        "    files = os.listdir(cls_path)[:3]  # pick first 3 images\n",
        "    for f in files:\n",
        "        img_path = os.path.join(cls_path, f)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            pred_class = torch.argmax(output, dim=1).item()\n",
        "        print(f\"{img_path.split('/')[-1]} -> Predicted class: {classes[pred_class]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4nsvUWeiND3",
        "outputId": "d96d5759-3a0b-4cfa-a976-0c2ecbeb162d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Te-gl_0210.jpg -> Predicted class: notumor\n",
            "Te-gl_0168.jpg -> Predicted class: notumor\n",
            "Te-gl_0251.jpg -> Predicted class: notumor\n",
            "Te-no_0112.jpg -> Predicted class: notumor\n",
            "Te-no_0397.jpg -> Predicted class: notumor\n",
            "Te-no_0183.jpg -> Predicted class: notumor\n",
            "Te-pi_0216.jpg -> Predicted class: notumor\n",
            "Te-pi_0107.jpg -> Predicted class: notumor\n",
            "Te-pi_0113.jpg -> Predicted class: notumor\n",
            "Te-me_0253.jpg -> Predicted class: notumor\n",
            "Te-me_0190.jpg -> Predicted class: notumor\n",
            "Te-me_0258.jpg -> Predicted class: notumor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/brain_tumor_hybrid_final.pth\")\n"
      ],
      "metadata": {
        "id": "3dA5lQkhii28"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "results = [\n",
        "    (\"Te-gl_0210.jpg\", \"notumor\"),\n",
        "    (\"Te-gl_0168.jpg\", \"notumor\"),\n",
        "    # add all predictions here or generate dynamically from your loop\n",
        "]\n",
        "\n",
        "with open(\"/content/predictions.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Image\", \"Predicted Class\"])\n",
        "    writer.writerows(results)\n"
      ],
      "metadata": {
        "id": "qGb0bnyLiozb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "dataset_path = \"/content/brain_tumor_dataset/Testing\"\n",
        "classes = ['glioma', 'notumor', 'pituitary', 'meningioma']\n",
        "\n",
        "results = []\n",
        "\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(dataset_path, cls)\n",
        "    files = os.listdir(cls_path)[:3]  # first 3 images\n",
        "    for f in files:\n",
        "        img_path = os.path.join(cls_path, f)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            pred_class = torch.argmax(output, dim=1).item()\n",
        "        results.append([f, classes[pred_class]])\n",
        "\n",
        "# Save to CSV\n",
        "with open(\"/content/predictions.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Image\", \"Predicted Class\"])\n",
        "    writer.writerows(results)\n",
        "\n",
        "print(\"✅ Model and predictions saved! Check /content/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AQC44DOjI3i",
        "outputId": "ce7af1a1-98f8-448d-b990-2b973340c59d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and predictions saved! Check /content/\n"
          ]
        }
      ]
    }
  ]
}